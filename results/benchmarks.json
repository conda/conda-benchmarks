{
    "conda_install.TimeInstall.time_explicit_install": {
        "code": "class TimeInstall:\n    def time_explicit_install(self, threads, latency, download_only=True):\n        socket = self.socket\n        prefix = os.path.join(self.td.name, f\"ex-{threads}-{latency}\")\n        port = socket.getsockname()[1]\n        requests.get(f\"http://127.0.0.1:{port}/latency/{latency}\")\n        specs = [\n            re.sub(\"(.*)(/.*/.*)\", f\"http://127.0.0.1:{port}\\\\2\", spec)\n            for spec in SPECS\n        ]\n        log.debug(\"%s\", specs)\n        os.environ[\"CONDA_PKGS_DIRS\"] = prefix\n        os.environ[\"CONDA_FETCH_THREADS\"] = str(threads)\n        reset_context()\n        print(f\"threads={threads}\")\n        if hasattr(context, \"fetch_threads\"):\n            assert context.fetch_threads == threads\n        conda.core.package_cache_data.DOWNLOAD_THREADS = threads\n        context.download_only = download_only\n        context.debug = 1\n        try:\n            conda.misc.explicit(\n                specs,\n                prefix,\n                verbose=False,\n                force_extract=True,\n                index_args=None,\n                index=None,\n            )\n        except conda.CondaExitZero:\n            log.info(\"cache prepared (not an error)\")\n\n    def setup(self, threads, latency, server=True):\n        self.td = tempfile.TemporaryDirectory()\n        if server:\n            self.socket = run_on_random_port()",
        "min_run_count": 2,
        "name": "conda_install.TimeInstall.time_explicit_install",
        "number": 0,
        "param_names": [
            "threads",
            "latency"
        ],
        "params": [
            [
                "1",
                "2",
                "3",
                "5",
                "7"
            ],
            [
                "0.0",
                "0.25"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "4de805fe8eda4b1904cf90edf9b73e5941ba1b0913a6994161ebc05ca41245fb",
        "warmup_time": -1
    },
    "download_asyncio.TimeDownloadPackages.time_download_strategy": {
        "code": "class TimeDownloadPackages:\n    def time_download_strategy(self, latency, strategy):\n        return {\n            \"aiohttp\": self.download_aiohttp,\n            \"threads\": self.download_threads,\n            \"serial\": self.download_serial,\n        }[strategy](latency)\n\n    def setup(self, latency=0.0, strategy=None):\n        self.tempdir = TemporaryDirectory(\"aiohttp\")\n        self.temppath = Path(self.tempdir.name)\n        log.info(\"Download to %s\", self.tempdir)\n        self._port = test_server.run_on_random_port().getsockname()[1]\n        requests.get(f\"http://127.0.0.1:{self.port}/latency/{latency}\")\n\n    def setup_cache(self):\n        \"\"\"\n        Called once per session.\n        self.value = x doesn't work here; benchmarks run in separate processes.\n        \"\"\"\n        test_server.base.mkdir(parents=True, exist_ok=True)\n    \n        for package in add_bz2(cheap[\"package\"]):\n            name = package[\"url\"].rpartition(\"/\")[-1]\n            if not (test_server.base / name).exists():\n                conda.exports.download(package[\"url\"], test_server.base / name)",
        "min_run_count": 2,
        "name": "download_asyncio.TimeDownloadPackages.time_download_strategy",
        "number": 0,
        "param_names": [
            "latency",
            "strategy"
        ],
        "params": [
            [
                "0.0",
                "0.01"
            ],
            [
                "'serial'",
                "'threads'",
                "'aiohttp'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "download_asyncio:125",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "ed437b590860e256074185f0b903e5a51f75f2efcb95233b7c3c4a8c758615a5",
        "warmup_time": -1
    },
    "extract.TimeExtract.time_extract": {
        "code": "class TimeExtract:\n    def time_extract(self, threads, format, lang):\n        if lang == \"rust\" and unpack_conda is None:\n            raise NotImplementedError()\n        if lang == \"rust\" and format == \".tar.bz2\":\n            raise NotImplementedError()\n        extract_fn = {\n            \"rust\": u2,\n            \"py\": conda_package_streaming.extract.extract,\n        }[lang]\n    \n        with ThreadPoolExecutor(threads) as executor:\n            for package in self.packages:\n                stem = package.name[: -len(format)]\n                dest_dir = pathlib.Path(self.td.name, stem)\n                print(package, str(dest_dir))\n                executor.submit(extract_fn, package, dest_dir)\n\n    def setup(self, threads, format, lang):\n        if lang == \"rust\" and format == \".tar.bz2\":\n            raise NotImplementedError()\n        self.td = TemporaryDirectory()\n    \n        # could use list from `conda-lock` in case more packages are in base\n        self.packages = list(base.glob(f\"*{format}\"))\n        if len(self.packages) < MINIMUM_PACKAGES:\n            raise NotImplementedError(f\"Not enough packages in {base}\")",
        "min_run_count": 2,
        "name": "extract.TimeExtract.time_extract",
        "number": 0,
        "param_names": [
            "threads",
            "format",
            "lang"
        ],
        "params": [
            [
                "1",
                "2",
                "3",
                "5",
                "7"
            ],
            [
                "'.conda'",
                "'.tar.bz2'"
            ],
            [
                "'py'",
                "'rust'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "0eb046ec5865369b3e52246499edd774a6b94937dc8a306240dd80eedb3a9e94",
        "warmup_time": -1
    },
    "extract.TrackSuite.track_streaming_versus_handling": {
        "code": "class TrackSuite:\n    def track_streaming_versus_handling(self):\n        \"\"\"\n        Compare conda-package-streaming time versus conda-package-handling (should be a number > 1)\n        \"\"\"\n        attempted = len(self.condas)\n        with TemporaryDirectory(\n            \"conda-package-streaming\"\n        ) as streaming, TemporaryDirectory(\"conda-package-handling\") as handling:\n    \n            # give faster streaming the cache disadvantage\n            begin = time.monotonic()\n            # revise self.condas down to the number extracted in no more than\u0153\n            # MAXIMUM_SECONDS\n            self.condas = extract_streaming(streaming, self.condas)\n            end = time.monotonic()\n            cps_time = end - begin\n    \n            actual = len(self.condas)\n            print(f\"'streaming' extracted {actual} out of {attempted} .conda's\")\n    \n            begin = time.monotonic()\n            self.condas = extract_handling(\n                handling, self.condas, time_limit=cps_time * 4\n            )\n            end = time.monotonic()\n            handling_time = end - begin\n    \n            actual = len(self.condas)\n            print(f\"'handling' extracted {actual} out of {attempted} .conda's\")\n    \n            return handling_time / cps_time\n\n    def setup(self):\n        self.condas = list(base.glob(\"*.conda\"))\n        if len(self.condas) < MINIMUM_PACKAGES:\n            raise NotImplementedError(\"Not enough .conda packages in ~/miniconda3/pkgs\")\n    \n        self.tarbz2 = list(base.glob(\"*.tar.bz2\"))",
        "name": "extract.TrackSuite.track_streaming_versus_handling",
        "param_names": [],
        "params": [],
        "timeout": 60.0,
        "type": "track",
        "unit": "speedup",
        "version": "d384feaa4082383c1f3872b820824ebbdbecd2d47ed818f8ff9623741d3f9199"
    },
    "extract.TrackSuite.track_streaming_versus_handling_tarbz2": {
        "code": "class TrackSuite:\n    def track_streaming_versus_handling_tarbz2(self):\n        \"\"\"\n        Compare conda-package-streaming time versus conda-package-handling (should be a number > 1)\n        \"\"\"\n        attempted = len(self.condas)\n        with TemporaryDirectory(\n            \"conda-package-streaming-bz2\"\n        ) as streaming, TemporaryDirectory(\"conda-package-handling-bz2\") as handling:\n    \n            # give faster streaming the cache disadvantage\n            begin = time.monotonic()\n            # revise self.condas down to the number extracted in no more than\u0153\n            # MAXIMUM_SECONDS\n            self.tarbz2 = extract_streaming(streaming, self.tarbz2)\n            end = time.monotonic()\n            cps_time = end - begin\n    \n            actual = len(self.condas)\n            print(f\"'streaming' extracted {actual} out of {attempted} .tar.bz2's\")\n    \n            begin = time.monotonic()\n            self.tarbz2 = extract_handling(\n                handling, self.tarbz2, time_limit=cps_time * 4\n            )\n            end = time.monotonic()\n            handling_time = end - begin\n    \n            actual = len(self.condas)\n            print(f\"'handling' extracted {actual} out of {attempted} .tar.bz2's\")\n    \n            return handling_time / cps_time\n\n    def setup(self):\n        self.condas = list(base.glob(\"*.conda\"))\n        if len(self.condas) < MINIMUM_PACKAGES:\n            raise NotImplementedError(\"Not enough .conda packages in ~/miniconda3/pkgs\")\n    \n        self.tarbz2 = list(base.glob(\"*.tar.bz2\"))",
        "name": "extract.TrackSuite.track_streaming_versus_handling_tarbz2",
        "param_names": [],
        "params": [],
        "timeout": 60.0,
        "type": "track",
        "unit": "speedup",
        "version": "cfb4bf5f3f7e90f04ebbf6294ea5132bc26bf5fbe56d6f3f56141cd92ec64442"
    },
    "peakmem_create_numpy_mkl": {
        "code": "@pytest.mark.benchmark\n@paramaterize_solver\ndef test_create_numpy_mkl(solver=SOLVER_DEFAULT):\n    execute_conda_cmd(CLEAN_INDEX_ARGS)\n    execute_conda_cmd(\n        CREATE_ARGS\n        + [\n            f\"--solver={solver}\",\n            \"-y\",\n            \"-n\",\n            random_env_name(),\n            \"-c\",\n            main,\n            \"python=3.6\",\n            \"numpy=1.15.2\",\n        ]\n    )",
        "name": "peakmem_create_numpy_mkl",
        "param_names": [
            "param1"
        ],
        "params": [
            [
                "'classic'",
                "'libmamba'"
            ]
        ],
        "timeout": 60.0,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "214b718cc302a6162bdf822a2d1f22f4c2b62b249066c260f07437ac1d8f9457"
    },
    "peakmem_create_numpy_openblas": {
        "code": "@pytest.mark.benchmark\n@paramaterize_solver\ndef test_create_numpy_openblas(solver=SOLVER_DEFAULT):\n    execute_conda_cmd(CLEAN_INDEX_ARGS)\n    execute_conda_cmd(\n        CREATE_ARGS\n        + [\n            f\"--solver={solver}\",\n            \"-y\",\n            \"-n\",\n            random_env_name(),\n            \"-c\",\n            main,\n            \"python=3.6\",\n            \"numpy=1.15.2\",\n            \"nomkl\",\n        ]\n    )",
        "name": "peakmem_create_numpy_openblas",
        "param_names": [
            "param1"
        ],
        "params": [
            [
                "'classic'",
                "'libmamba'"
            ]
        ],
        "timeout": 60.0,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "a99b523ded0d6cd8c638a685693152bbce69cdd89e51b2e90e1fc4ccbbcd75f1"
    },
    "peakmem_create_python": {
        "code": "@pytest.mark.benchmark\n@paramaterize_solver\ndef test_create_python(solver=SOLVER_DEFAULT):\n    execute_conda_cmd(CLEAN_INDEX_ARGS)\n    execute_conda_cmd(\n        CREATE_ARGS\n        + [\n            f\"--solver={solver}\",\n            \"-y\",\n            \"-n\",\n            random_env_name(),\n            \"-c\",\n            main,\n            \"python=3.6\",\n        ]\n    )",
        "name": "peakmem_create_python",
        "param_names": [
            "param1"
        ],
        "params": [
            [
                "'classic'",
                "'libmamba'"
            ]
        ],
        "timeout": 60.0,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "61700a79a1c9bbe7420938c2225ee3cbaa150591940f872fca749379430f01d5"
    },
    "peakmem_create_python_boost": {
        "code": "@pytest.mark.benchmark\n@paramaterize_solver\ndef test_create_python_boost(solver=SOLVER_DEFAULT):\n    execute_conda_cmd(CLEAN_INDEX_ARGS)\n    execute_conda_cmd(\n        CREATE_ARGS\n        + [\n            f\"--solver={solver}\",\n            \"-y\",\n            \"-n\",\n            random_env_name(),\n            \"-c\",\n            main,\n            \"python=3.6\",\n            \"libboost\",\n        ]\n    )",
        "name": "peakmem_create_python_boost",
        "param_names": [
            "param1"
        ],
        "params": [
            [
                "'classic'",
                "'libmamba'"
            ]
        ],
        "timeout": 60.0,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "655976de94b89433baaecbc7cc0dd3e1a08dce4d4eb8d0fc442baabd4bbe99c0"
    },
    "peakmem_solve_anaconda_53": {
        "code": "@pytest.mark.benchmark\n@paramaterize_solver\ndef test_solve_anaconda_53(solver=SOLVER_DEFAULT):\n    execute_conda_cmd(CLEAN_INDEX_ARGS)\n    execute_conda_cmd(\n        SOLVE_ARGS + [f\"--solver={solver}\", \"-c\", main, \"anaconda=5.3.0\"]\n    )",
        "name": "peakmem_solve_anaconda_53",
        "param_names": [
            "param1"
        ],
        "params": [
            [
                "'classic'",
                "'libmamba'"
            ]
        ],
        "timeout": 60.0,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "5b8600e818025cd7cd6518748d577d02d4f727c5496a24ac158481afbbd64e61"
    },
    "peakmem_solve_r_essentials_r_base_conda_forge": {
        "code": "@pytest.mark.benchmark\n@paramaterize_solver\ndef test_solve_r_essentials_r_base_conda_forge(solver=SOLVER_DEFAULT):\n    execute_conda_cmd(CLEAN_INDEX_ARGS)\n    execute_conda_cmd(\n        SOLVE_ARGS\n        + [\n            f\"--solver={solver}\",\n            \"-c\",\n            conda_forge,\n            \"-c\",\n            main,\n            \"-c\",\n            r,\n            \"r-essentials\",\n            \"r-base\",\n        ]\n    )",
        "name": "peakmem_solve_r_essentials_r_base_conda_forge",
        "param_names": [
            "param1"
        ],
        "params": [
            [
                "'classic'",
                "'libmamba'"
            ]
        ],
        "timeout": 60.0,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "fcd8c26e72943f67b60d7dec8d356d3f842adfc9ffd9754bd59786c411884ec5"
    },
    "peakmem_solve_r_essentials_r_base_defaults": {
        "code": "@pytest.mark.benchmark\n@paramaterize_solver\ndef test_solve_r_essentials_r_base_defaults(solver=SOLVER_DEFAULT):\n    execute_conda_cmd(CLEAN_INDEX_ARGS)\n    execute_conda_cmd(\n        SOLVE_ARGS\n        + [f\"--solver={solver}\", \"-c\", main, \"-c\", r, \"r-essentials\", \"r-base\"]\n    )",
        "name": "peakmem_solve_r_essentials_r_base_defaults",
        "param_names": [
            "param1"
        ],
        "params": [
            [
                "'classic'",
                "'libmamba'"
            ]
        ],
        "timeout": 60.0,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "52c926f78bde8798cdea3e9100d80378fc17b3a3f60e8dd96758e63b97abfcfe"
    },
    "run_versus_activate.time_conda_run": {
        "code": "def time_conda_run():\n    \"\"\"\n    May need to be string form of benchmark to catch import times?\n    \"\"\"\n    from conda.testing.helpers import run_inprocess_conda_command\n\n    run_inprocess_conda_command(\n        \"conda run -n base python -V\",\n        disallow_stderr=False,\n    )",
        "min_run_count": 2,
        "name": "run_versus_activate.time_conda_run",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "ce014c648a566030aac63b393c16c9333f0b90cbf380a3b537e552e501941096",
        "warmup_time": -1
    },
    "subdir_data.TimeSubdirData.time_load_json": {
        "code": "class TimeSubdirData:\n    def time_load_json(self):\n        os.environ[\"CONDA_PKGS_DIRS\"] = str(CONDA_PKGS_DIR)\n        os.environ[\"CONDA_DEFAULT_THREADS\"] = \"1\"\n        SubdirData.clear_cached_local_channel_data()\n        reset_context()\n        context.offline = True\n        channel = Channel(CHANNEL_URL)\n        subdir = SubdirDataNoPickle(channel)\n        subdir._read_local_repdata(MOD_STAMP[\"_etag\"], MOD_STAMP[\"_mod\"])\n\n    def setup(self):\n        if not REPODATA_FILENAME.exists():\n            REPODATA_FILENAME.parent.mkdir(exist_ok=True)\n            # fake out\n            (base / \"noarch\").mkdir(exist_ok=True)\n            (base / \"noarch\" / \"repodata.json\").write_text(\"{}\")\n            (base / \"noarch\" / \"repodata.json.bz2\").write_text(\"\")\n            # do we have a frozen large-ish repodata.json or can we fake one?\n            conda.exports.download(\n                \"https://repo.anaconda.com/pkgs/main/osx-64/repodata.json\",\n                REPODATA_FILENAME,\n            )",
        "min_run_count": 2,
        "name": "subdir_data.TimeSubdirData.time_load_json",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "35f66376e8016a26a66a7984f7d6f7028ad2359ab1f18287fb448fe4156087a2",
        "warmup_time": -1
    },
    "subdir_data.TimeSubdirData.time_load_json_query_all": {
        "code": "class TimeSubdirData:\n    def time_load_json_query_all(self):\n        os.environ[\"CONDA_PKGS_DIRS\"] = str(CONDA_PKGS_DIR)\n        os.environ[\"CONDA_DEFAULT_THREADS\"] = \"1\"\n        SubdirData.clear_cached_local_channel_data()\n        reset_context()\n        context.offline = True\n        channel = Channel(CHANNEL_URL)\n        subdir = SubdirDataNoPickle(channel)\n        subdir._read_local_repdata(MOD_STAMP[\"_etag\"], MOD_STAMP[\"_mod\"])\n        subdir.query(\"[version=1.0]\")\n\n    def setup(self):\n        if not REPODATA_FILENAME.exists():\n            REPODATA_FILENAME.parent.mkdir(exist_ok=True)\n            # fake out\n            (base / \"noarch\").mkdir(exist_ok=True)\n            (base / \"noarch\" / \"repodata.json\").write_text(\"{}\")\n            (base / \"noarch\" / \"repodata.json.bz2\").write_text(\"\")\n            # do we have a frozen large-ish repodata.json or can we fake one?\n            conda.exports.download(\n                \"https://repo.anaconda.com/pkgs/main/osx-64/repodata.json\",\n                REPODATA_FILENAME,\n            )",
        "min_run_count": 2,
        "name": "subdir_data.TimeSubdirData.time_load_json_query_all",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "154d0d31b099aeecd22b30343f902ab794ab9b232afd6f40368db1dc6eb4c352",
        "warmup_time": -1
    },
    "subdir_data.TimeSubdirData.time_load_json_query_one": {
        "code": "class TimeSubdirData:\n    def time_load_json_query_one(self):\n        os.environ[\"CONDA_PKGS_DIRS\"] = str(CONDA_PKGS_DIR)\n        os.environ[\"CONDA_DEFAULT_THREADS\"] = \"1\"\n        SubdirData.clear_cached_local_channel_data()\n        reset_context()\n        context.offline = True\n        channel = Channel(CHANNEL_URL)\n        subdir = SubdirDataNoPickle(channel)\n        subdir._read_local_repdata(MOD_STAMP[\"_etag\"], MOD_STAMP[\"_mod\"])\n        subdir.query(\"python\")\n\n    def setup(self):\n        if not REPODATA_FILENAME.exists():\n            REPODATA_FILENAME.parent.mkdir(exist_ok=True)\n            # fake out\n            (base / \"noarch\").mkdir(exist_ok=True)\n            (base / \"noarch\" / \"repodata.json\").write_text(\"{}\")\n            (base / \"noarch\" / \"repodata.json.bz2\").write_text(\"\")\n            # do we have a frozen large-ish repodata.json or can we fake one?\n            conda.exports.download(\n                \"https://repo.anaconda.com/pkgs/main/osx-64/repodata.json\",\n                REPODATA_FILENAME,\n            )",
        "min_run_count": 2,
        "name": "subdir_data.TimeSubdirData.time_load_json_query_one",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "63b2f23eb52638a33eb7db04b302cabf427550fdb374166978b6514cf9f99351",
        "warmup_time": -1
    },
    "subdir_data.TimeSubdirData.time_load_pickle": {
        "code": "class TimeSubdirData:\n    def time_load_pickle(self):\n        os.environ[\"CONDA_PKGS_DIRS\"] = str(CONDA_PKGS_DIR)\n        os.environ[\"CONDA_DEFAULT_THREADS\"] = \"1\"\n        SubdirData.clear_cached_local_channel_data()\n        reset_context()\n        context.offline = True\n        channel = Channel(CHANNEL_URL)\n        sd = SubdirData(channel)\n        sd._read_pickled(MOD_STAMP[\"_etag\"], MOD_STAMP[\"_mod\"])\n\n    def setup(self):\n        if not REPODATA_FILENAME.exists():\n            REPODATA_FILENAME.parent.mkdir(exist_ok=True)\n            # fake out\n            (base / \"noarch\").mkdir(exist_ok=True)\n            (base / \"noarch\" / \"repodata.json\").write_text(\"{}\")\n            (base / \"noarch\" / \"repodata.json.bz2\").write_text(\"\")\n            # do we have a frozen large-ish repodata.json or can we fake one?\n            conda.exports.download(\n                \"https://repo.anaconda.com/pkgs/main/osx-64/repodata.json\",\n                REPODATA_FILENAME,\n            )",
        "min_run_count": 2,
        "name": "subdir_data.TimeSubdirData.time_load_pickle",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "bf8d3ae4aa83e4494d54ba756a12997cb22c0b68ff8a89b70ab2cef8604f66af",
        "warmup_time": -1
    },
    "subdir_data.TimeSubdirData.time_save_pickle": {
        "code": "class TimeSubdirData:\n    def time_save_pickle(self):\n        os.environ[\"CONDA_PKGS_DIRS\"] = str(CONDA_PKGS_DIR)\n        os.environ[\"CONDA_DEFAULT_THREADS\"] = \"1\"\n        SubdirData.clear_cached_local_channel_data()\n        reset_context()\n        context.offline = True\n        channel = Channel(CHANNEL_URL)\n        sd = SubdirData(channel)\n        sd._pickle_me()\n\n    def setup(self):\n        if not REPODATA_FILENAME.exists():\n            REPODATA_FILENAME.parent.mkdir(exist_ok=True)\n            # fake out\n            (base / \"noarch\").mkdir(exist_ok=True)\n            (base / \"noarch\" / \"repodata.json\").write_text(\"{}\")\n            (base / \"noarch\" / \"repodata.json.bz2\").write_text(\"\")\n            # do we have a frozen large-ish repodata.json or can we fake one?\n            conda.exports.download(\n                \"https://repo.anaconda.com/pkgs/main/osx-64/repodata.json\",\n                REPODATA_FILENAME,\n            )",
        "min_run_count": 2,
        "name": "subdir_data.TimeSubdirData.time_save_pickle",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "6fc984f0a7d013480570252a7f2988e0b756fcf4ff76696d79414cbe5995497a",
        "warmup_time": -1
    },
    "subdir_data.TimeSubdirData.time_subdir_data": {
        "code": "class TimeSubdirData:\n    def time_subdir_data(self):\n        channel = Channel(f\"file://{base}\", platform=\"osx-64\")\n        SubdirData.clear_cached_local_channel_data()\n    \n        sd_a = SubdirData(channel)\n        assert sd_a.query_all(\"zlib =1.2.11\")\n\n    def setup(self):\n        if not REPODATA_FILENAME.exists():\n            REPODATA_FILENAME.parent.mkdir(exist_ok=True)\n            # fake out\n            (base / \"noarch\").mkdir(exist_ok=True)\n            (base / \"noarch\" / \"repodata.json\").write_text(\"{}\")\n            (base / \"noarch\" / \"repodata.json.bz2\").write_text(\"\")\n            # do we have a frozen large-ish repodata.json or can we fake one?\n            conda.exports.download(\n                \"https://repo.anaconda.com/pkgs/main/osx-64/repodata.json\",\n                REPODATA_FILENAME,\n            )",
        "min_run_count": 2,
        "name": "subdir_data.TimeSubdirData.time_subdir_data",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "7b06ce8f4c53edf9bb515f7f095b3fd5b6bfc9a2170e059bc8b38b3d28d67021",
        "warmup_time": -1
    },
    "time_create_numpy_mkl": {
        "code": "@pytest.mark.benchmark\n@paramaterize_solver\ndef test_create_numpy_mkl(solver=SOLVER_DEFAULT):\n    execute_conda_cmd(CLEAN_INDEX_ARGS)\n    execute_conda_cmd(\n        CREATE_ARGS\n        + [\n            f\"--solver={solver}\",\n            \"-y\",\n            \"-n\",\n            random_env_name(),\n            \"-c\",\n            main,\n            \"python=3.6\",\n            \"numpy=1.15.2\",\n        ]\n    )",
        "min_run_count": 2,
        "name": "time_create_numpy_mkl",
        "number": 0,
        "param_names": [
            "param1"
        ],
        "params": [
            [
                "'classic'",
                "'libmamba'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "214b718cc302a6162bdf822a2d1f22f4c2b62b249066c260f07437ac1d8f9457",
        "warmup_time": -1
    },
    "time_create_numpy_openblas": {
        "code": "@pytest.mark.benchmark\n@paramaterize_solver\ndef test_create_numpy_openblas(solver=SOLVER_DEFAULT):\n    execute_conda_cmd(CLEAN_INDEX_ARGS)\n    execute_conda_cmd(\n        CREATE_ARGS\n        + [\n            f\"--solver={solver}\",\n            \"-y\",\n            \"-n\",\n            random_env_name(),\n            \"-c\",\n            main,\n            \"python=3.6\",\n            \"numpy=1.15.2\",\n            \"nomkl\",\n        ]\n    )",
        "min_run_count": 2,
        "name": "time_create_numpy_openblas",
        "number": 0,
        "param_names": [
            "param1"
        ],
        "params": [
            [
                "'classic'",
                "'libmamba'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "a99b523ded0d6cd8c638a685693152bbce69cdd89e51b2e90e1fc4ccbbcd75f1",
        "warmup_time": -1
    },
    "time_create_python": {
        "code": "@pytest.mark.benchmark\n@paramaterize_solver\ndef test_create_python(solver=SOLVER_DEFAULT):\n    execute_conda_cmd(CLEAN_INDEX_ARGS)\n    execute_conda_cmd(\n        CREATE_ARGS\n        + [\n            f\"--solver={solver}\",\n            \"-y\",\n            \"-n\",\n            random_env_name(),\n            \"-c\",\n            main,\n            \"python=3.6\",\n        ]\n    )",
        "min_run_count": 2,
        "name": "time_create_python",
        "number": 0,
        "param_names": [
            "param1"
        ],
        "params": [
            [
                "'classic'",
                "'libmamba'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "61700a79a1c9bbe7420938c2225ee3cbaa150591940f872fca749379430f01d5",
        "warmup_time": -1
    },
    "time_create_python_boost": {
        "code": "@pytest.mark.benchmark\n@paramaterize_solver\ndef test_create_python_boost(solver=SOLVER_DEFAULT):\n    execute_conda_cmd(CLEAN_INDEX_ARGS)\n    execute_conda_cmd(\n        CREATE_ARGS\n        + [\n            f\"--solver={solver}\",\n            \"-y\",\n            \"-n\",\n            random_env_name(),\n            \"-c\",\n            main,\n            \"python=3.6\",\n            \"libboost\",\n        ]\n    )",
        "min_run_count": 2,
        "name": "time_create_python_boost",
        "number": 0,
        "param_names": [
            "param1"
        ],
        "params": [
            [
                "'classic'",
                "'libmamba'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "655976de94b89433baaecbc7cc0dd3e1a08dce4d4eb8d0fc442baabd4bbe99c0",
        "warmup_time": -1
    },
    "time_solve_anaconda_53": {
        "code": "@pytest.mark.benchmark\n@paramaterize_solver\ndef test_solve_anaconda_53(solver=SOLVER_DEFAULT):\n    execute_conda_cmd(CLEAN_INDEX_ARGS)\n    execute_conda_cmd(\n        SOLVE_ARGS + [f\"--solver={solver}\", \"-c\", main, \"anaconda=5.3.0\"]\n    )",
        "min_run_count": 2,
        "name": "time_solve_anaconda_53",
        "number": 0,
        "param_names": [
            "param1"
        ],
        "params": [
            [
                "'classic'",
                "'libmamba'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "5b8600e818025cd7cd6518748d577d02d4f727c5496a24ac158481afbbd64e61",
        "warmup_time": -1
    },
    "time_solve_r_essentials_r_base_conda_forge": {
        "code": "@pytest.mark.benchmark\n@paramaterize_solver\ndef test_solve_r_essentials_r_base_conda_forge(solver=SOLVER_DEFAULT):\n    execute_conda_cmd(CLEAN_INDEX_ARGS)\n    execute_conda_cmd(\n        SOLVE_ARGS\n        + [\n            f\"--solver={solver}\",\n            \"-c\",\n            conda_forge,\n            \"-c\",\n            main,\n            \"-c\",\n            r,\n            \"r-essentials\",\n            \"r-base\",\n        ]\n    )",
        "min_run_count": 2,
        "name": "time_solve_r_essentials_r_base_conda_forge",
        "number": 0,
        "param_names": [
            "param1"
        ],
        "params": [
            [
                "'classic'",
                "'libmamba'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "fcd8c26e72943f67b60d7dec8d356d3f842adfc9ffd9754bd59786c411884ec5",
        "warmup_time": -1
    },
    "time_solve_r_essentials_r_base_defaults": {
        "code": "@pytest.mark.benchmark\n@paramaterize_solver\ndef test_solve_r_essentials_r_base_defaults(solver=SOLVER_DEFAULT):\n    execute_conda_cmd(CLEAN_INDEX_ARGS)\n    execute_conda_cmd(\n        SOLVE_ARGS\n        + [f\"--solver={solver}\", \"-c\", main, \"-c\", r, \"r-essentials\", \"r-base\"]\n    )",
        "min_run_count": 2,
        "name": "time_solve_r_essentials_r_base_defaults",
        "number": 0,
        "param_names": [
            "param1"
        ],
        "params": [
            [
                "'classic'",
                "'libmamba'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "52c926f78bde8798cdea3e9100d80378fc17b3a3f60e8dd96758e63b97abfcfe",
        "warmup_time": -1
    },
    "version": 2
}